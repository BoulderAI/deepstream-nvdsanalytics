FROM nvcr.io/nvidia/deepstream-l4t:5.0.1-20.09-base AS deepstream-deploy
# Install tensorflow gpu to support building output uff files at runtime 
# from the development container.  We won't need this on the production container
# For Jetson see https://elinux.org/Jetson_Zoo#TensorFlow and
# https://docs.nvidia.com/deeplearning/frameworks/install-tf-jetson-platform/index.html#prereqs
RUN apt-get update && apt-get install -y python3-dev
RUN apt-get update && apt-get install -y python3-pip && pip3 install -U pip testresources setuptools==49.6.0
RUN apt-get update && apt-get install -y libhdf5-serial-dev hdf5-tools \
	libhdf5-dev zlib1g-dev zip libjpeg8-dev liblapack-dev libblas-dev gfortran
RUN apt-get update && pip3 install -U numpy==1.16.1 future==0.18.2 mock==3.0.5 \
	h5py==2.10.0 keras_preprocessing==1.1.1 keras_applications==1.0.8 gast==0.2.2 futures protobuf pybind11
RUN pip3 install --pre --extra-index-url https://developer.download.nvidia.com/compute/redist/jp/v44 'tensorflow<2'

# With the samples container I hit the bug at
# https://forums.developer.nvidia.com/t/nvcaffeparser-h-missing-in-docker-for-deepstream-5-0-objectdetector-yolo/154623/5?u=danwalkes1
# attmpting to build the nvdsinfer plugin.
FROM nvcr.io/nvidia/deepstream-l4t:5.0.1-20.09-samples AS deepstream-build
 
RUN apt-get update && apt-get install -y build-essential
RUN apt-get install -y libgstreamer1.0-dev libgstrtspserver-1.0-dev
RUN apt-get install -y libjson-glib-dev
# Additional dependencies for building uff files within the container
# We won't need these in production
RUN apt-get install -y wget

RUN mkdir -p /usr/src/app/src

COPY . /usr/src/app/src

WORKDIR /usr/src/app/src

RUN make -f Makefile.ds

RUN cd nvdsinfer_custom_impl_ssd && \
    CUDA_VER=10.2 make

FROM deepstream-deploy
# Not needed in production container, only here for test purposes
COPY --from=deepstream-build /opt/nvidia/deepstream/deepstream/samples/streams/sample_1080p_h265.mp4 \
	/opt/nvidia/deepstream/deepstream/samples/streams/sample_1080p_h265.mp4
# This is the only way I've found to get the tensorrt source dir copied into
# the runtime container, for dynamic conversion from .pb to .uff.  It could
# be simplified and could be removed for production images if we don't need
# to support conversion from .pb to .uff
COPY --from=deepstream-build /usr/src/ \
    /usr/src/

RUN mkdir -p /usr/src/app/ && \
    mkdir -p /usr/src/app/lib/

COPY --from=deepstream-build /usr/src/app/src/nvdsinfer_custom_impl_ssd/*.so \
        /usr/src/app/lib/

COPY --from=deepstream-build /usr/src/app/src/*.sh /usr/src/app/
COPY --from=deepstream-build /usr/src/app/src/deepstream-app /usr/src/app/

# Not needed in production containers
COPY --from=deepstream-build /usr/src/app/src/cfg-deepstream-default \
    /usr/src/app/cfg-deepstream-default
COPY --from=deepstream-build /usr/src/app/src/cfg-model-default \
    /usr/src/app/cfg-model-default


WORKDIR /usr/src/app

ENTRYPOINT [ "/usr/src/app/initScript.sh" ]
